{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM7rQ5d1DPA-",
        "outputId": "9fde6791-1e1c-4734-aea9-33fc490783f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSjJHXVaDV6f",
        "outputId": "1e98dcbc-e7dc-4601-aecd-b9ad3d8bd483"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.5 MB 29.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 182 kB 70.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.6 MB 54.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR2wH8eO-Cko",
        "outputId": "d3c66119-7124-406c-ddb8-25d4227c835b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "import re\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score\n",
        "\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed: int):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "seed = 3407\n",
        "seed_everything(seed)\n",
        "\n",
        "stop_en = stopwords.words('english')\n",
        "stop_ru = stopwords.words('russian')"
      ],
      "metadata": {
        "id": "t4Z_4NfVB6gq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "V0FPR8GRD1P_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
        "\n",
        "model = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased\").to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi0fRzB9B6i8",
        "outputId": "2a66c3de-8352-4fac-9d83-30e272e84de5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/ASR/lemma/lemma_train.csv\"\n",
        "\n",
        "df = pd.read_csv(filename)"
      ],
      "metadata": {
        "id": "uIER2H1QB6lS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"clean_text\", \"clipTarget\"]\n",
        "df = df[columns]\n",
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zWvZDrcFCLU3",
        "outputId": "7fd524b6-8df9-400b-8b74-20aaf710f1f8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               clean_text clipTarget\n",
              "85686                       comics clock ‚è∞ –Ω–∞–∑–∞–¥ –±—É–¥—É—â–µ–µüò±      BOOKS\n",
              "159106          —Ö–ª–µ–± –ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π —É–≥–ª—è—Ö –ø–µ—Å–∫–∞–º–∏ –ø—É—Å—Ç—ã–Ω–∏     TRAVEL\n",
              "130368                                              ‚ö°Ô∏è ‚õàüå©     MOVIES\n",
              "110892  –±–µ—Ä–∏ –¥–æ—Å–∫—É –≤—ã—Ö–æ–¥–∏ —É–ª–∏—Ü—É ü§ç —Å–µ—Ä—Ñ—Å–∫–µ–π—Ç —Å—ë—Ä—Ñ—Å–∫–µ–π—Ç–∏...      SPORT\n",
              "120416  –∫—Ä–∞—Ç–∫–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ–º–æ—â—å—é –∫–ª–∏–Ω—á–∞ –≥—Ä–∞–º–æ—Ç–Ω–æ–≥–æ ...      SPORT"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74c7f0f9-d27e-4746-bf47-84d73985c0ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>clipTarget</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>85686</th>\n",
              "      <td>comics clock ‚è∞ –Ω–∞–∑–∞–¥ –±—É–¥—É—â–µ–µüò±</td>\n",
              "      <td>BOOKS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159106</th>\n",
              "      <td>—Ö–ª–µ–± –ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π —É–≥–ª—è—Ö –ø–µ—Å–∫–∞–º–∏ –ø—É—Å—Ç—ã–Ω–∏</td>\n",
              "      <td>TRAVEL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130368</th>\n",
              "      <td>‚ö°Ô∏è ‚õàüå©</td>\n",
              "      <td>MOVIES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110892</th>\n",
              "      <td>–±–µ—Ä–∏ –¥–æ—Å–∫—É –≤—ã—Ö–æ–¥–∏ —É–ª–∏—Ü—É ü§ç —Å–µ—Ä—Ñ—Å–∫–µ–π—Ç —Å—ë—Ä—Ñ—Å–∫–µ–π—Ç–∏...</td>\n",
              "      <td>SPORT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120416</th>\n",
              "      <td>–∫—Ä–∞—Ç–∫–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ–º–æ—â—å—é –∫–ª–∏–Ω—á–∞ –≥—Ä–∞–º–æ—Ç–Ω–æ–≥–æ ...</td>\n",
              "      <td>SPORT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74c7f0f9-d27e-4746-bf47-84d73985c0ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74c7f0f9-d27e-4746-bf47-84d73985c0ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74c7f0f9-d27e-4746-bf47-84d73985c0ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)\n",
        "df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "r-1mk2QhCLXD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/ASR/classes.json\", \"r\") as f:\n",
        "    cls2index = json.load(f)"
      ],
      "metadata": {
        "id": "38z8ombbCLZg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DescriptionDataset(Dataset):\n",
        "    def __init__(self, text, target):\n",
        "        self.text = text\n",
        "        self.target = target\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        sent = self.text[item]\n",
        "        target = cls2index[self.target[item]]\n",
        "        with torch.no_grad():\n",
        "            tokens = tokenizer(sent, return_tensors=\"pt\")\n",
        "            for key, val in tokens.items():\n",
        "                tokens[key] = val.to(device)\n",
        "            embeds = model(**tokens)[\"pooler_output\"].squeeze(0) # 768\n",
        "        return embeds, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "dataset = DescriptionDataset(df[\"clean_text\"].to_list(), df[\"clipTarget\"].to_list())\n",
        "dataloader = DataLoader(dataset=dataset, shuffle=True, batch_size=512)"
      ],
      "metadata": {
        "id": "tSvr6NPeCLb2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim: int = 768, hidden_dim: int = 512, output_dim: int = 52, p: float = 0.5):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        return self.fc3(x)"
      ],
      "metadata": {
        "id": "bXg2Qw6kCSUv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Classifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 10e-3\n",
        "opt = optim.Adam(classifier.parameters(), lr=lr)\n",
        "EPOCHS = 10\n",
        "losses = []\n",
        "for epoch in range(EPOCHS):\n",
        "    loss_acc = []\n",
        "    running_score = 0\n",
        "    for input, output in tqdm(dataloader):\n",
        "        opt.zero_grad()\n",
        "        input = input#.to(device)\n",
        "        output = output.to(device)\n",
        "\n",
        "        preds = classifier(input)\n",
        "        loss = criterion(preds, output)\n",
        "\n",
        "        loss_acc.append(loss.detach().cpu().item())\n",
        "        loss.backward()\n",
        "\n",
        "        output = output.detach().cpu().numpy()\n",
        "        preds = preds.argmax(dim=1).detach().cpu().numpy()\n",
        "        running_score += f1_score(output, preds, average='macro')\n",
        "\n",
        "        opt.step()\n",
        "    loss_acc = np.mean(loss_acc)\n",
        "    score = running_score / len(dataloader)\n",
        "    print(f\"Epoch: {epoch + 1}/{EPOCHS} | Loss :{loss_acc:.4f} | F1-score :{score:.4f}\")\n",
        "    torch.save(model.state_dict(), f\"/content/drive/MyDrive/ASR/rubert/classifier_e{epoch}.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu_vs_ZgCSZf",
        "outputId": "6bde0620-8da3-452f-abc1-92733c2fdc4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 440/440 [44:10<00:00,  6.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10 | Loss :3.0098 | F1-score :0.1300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 440/440 [43:33<00:00,  5.94s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2/10 | Loss :2.7540 | F1-score :0.1943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 440/440 [43:52<00:00,  5.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3/10 | Loss :2.6974 | F1-score :0.2149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 440/440 [43:32<00:00,  5.94s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4/10 | Loss :2.6666 | F1-score :0.2238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 440/440 [46:02<00:00,  6.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5/10 | Loss :2.6456 | F1-score :0.2305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 440/440 [45:19<00:00,  6.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6/10 | Loss :2.6405 | F1-score :0.2315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 378/440 [38:45<06:11,  6.00s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3HDaeD47CSby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ceE98EO7CLea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8pXL-bMpCLg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y6gTfpzECLjR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}